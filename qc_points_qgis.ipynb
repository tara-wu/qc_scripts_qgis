{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e580909-bb3f-4f8c-b50a-3620d5318b61",
   "metadata": {},
   "source": [
    "## Quality Control Script for QGIS Points Layer\n",
    "by Tara Wu, Spring 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbb0ec-7656-4c25-ac89-3be274883dc2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Purpose:</b>  This script performs a series of quality checks for point features in QGIS. Specifically, it checks for the following: \n",
    "<ul>\n",
    "    <li>nulls in specific fields </li>\n",
    "    <li>invalid dates</li>\n",
    "    <li>orphaned related records</li>\n",
    "    <li>missing related records </li>\n",
    "    <li> duplicates due to sync error,</li> \n",
    "    <li>inputs not in domains, repetitive attributes per user </li>\n",
    "    <li>offline data has been synced</li>\n",
    "    <li>proximity to trails/features</li> \n",
    "    <li>matching collector and region</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9637f6e-f874-4dcf-9116-66118cba6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PARAMETERS ===\n",
    "\n",
    "# === import modules ===\n",
    "import datetime\n",
    "import importlib\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# check for required packages\n",
    "required_packages = [\n",
    "    \"os\",\n",
    "    \"datetime\",\n",
    "    \"logging\",\n",
    "    \"sys\",\n",
    "    \"pandas\",\n",
    "    \"geopandas\",\n",
    "    \"shapely\",\n",
    "]\n",
    "\n",
    "for pkg in required_packages:\n",
    "    if importlib.util.find_spec(pkg) is None:\n",
    "        print(f\"Missing package '{pkg}'. Install via: pip install {pkg}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "# === output setup ===\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "DATA_FOLDER = os.path.join(BASE_DIR, \"data\")\n",
    "OUTPUT_FOLDER = os.path.join(BASE_DIR, \"outputs\")\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# input files\n",
    "POINTS_FILE = os.path.join(DATA_FOLDER, \"points.gpkg\")  # Update with your layer\n",
    "RELATED_TABLE_FILE = os.path.join(DATA_FOLDER, \"related.csv\")  # Optional related table\n",
    "\n",
    "# project start date\n",
    "PROJECT_START_YEAR = 2025\n",
    "PROJECT_START_MONTH = 5\n",
    "PROJECT_START_DAY = 5\n",
    "\n",
    "# thresholds / buffers\n",
    "BUFFER_FT = 100\n",
    "THRESHOLD = 0.9  # for repetitive values\n",
    "\n",
    "# required fields\n",
    "POINTS_REQUIRED_FIELDS = [\"GlobalID\", \"created_user\", \"created_date\", \"SHAPE\"]\n",
    "RELATED_REQUIRED_FIELDS = [\"defGlobalID\", \"Feature\", \"Feature_Action\"]\n",
    "\n",
    "# fields for sync/repetitive checks\n",
    "POINTS_SYNC_FIELDS = [\"created_date\", \"created_user\"]\n",
    "RELATED_SYNC_FIELDS = [\"CreationDate\", \"Creator\"]\n",
    "\n",
    "POINTS_REP_FIELDS = [\"Evaluation_Code\", \"Deficiency_Length\"]\n",
    "RELATED_REP_FIELDS = [\"Feature\"]\n",
    "\n",
    "# domains\n",
    "POINTS_DOMAINS = {\n",
    "    \"State\": [\"MA\", \"ME\", \"CT\", \"NH\", \"VT\"],\n",
    "    \"Club\": [\"AMC\", \"AMC-CT\", \"AMC-WMA\", \"DOC\", \"GMC\", \"MATC\", \"RMC\"],\n",
    "    \"Evaluation_Code\": [\"Low\", \"Moderate\", \"High\", None],\n",
    "    \"OnsiteMaterials\": [\"Yes\", \"No\", \"Maybe\", None],\n",
    "    \"ConsiderRelocation\": [\"Yes\", \"No\", None],\n",
    "}\n",
    "\n",
    "RELATED_DOMAINS = {\n",
    "    \"Feature\": [\"Trail\", \"Bridge\", \"Shelter\", None],\n",
    "    \"FeatureAction\": [\"Build Add\", \"Repair Replace\", \"Remove\", None],\n",
    "    \"Units\": [\"Each\", \"LinearFeet\", \"SquareFeet\", None],\n",
    "    \"onsitematerials\": [\"Yes\", \"No\", \"Maybe\", None],\n",
    "}\n",
    "\n",
    "# collector-region dictionary\n",
    "COLLECTOR_DICT = {\n",
    "    \"twu_ATConservancy\": [\"MATC\"],\n",
    "    \"userB\": [\"RMC\", \"AMC\", \"DOC\"],\n",
    "    \"userC\": [\"GMC\"],\n",
    "    \"userD\": [\"AMC-WMA\"],\n",
    "    \"userE\": [\"AMC-CT\"],\n",
    "}\n",
    "\n",
    "# output column order\n",
    "POINTS_ERROR_ORDER = [\n",
    "    \"error_type\",\n",
    "    \"error_desc\",\n",
    "    \"OBJECTID\",\n",
    "    \"GlobalID\",\n",
    "    \"created_user\",\n",
    "    \"created_date\",\n",
    "    \"Deficiency_Length\",\n",
    "    \"Evaluation_Code\",\n",
    "    \"ConsiderRelocation\",\n",
    "    \"Notes\",\n",
    "    \"OnsiteMaterials\",\n",
    "    \"RelativeLinearLocation\",\n",
    "    \"SHAPE\",\n",
    "    \"MileMarker\",\n",
    "    \"State\",\n",
    "    \"LandOwner\",\n",
    "    \"OwnershipType\",\n",
    "    \"Club\",\n",
    "]\n",
    "\n",
    "RELATED_ERROR_ORDER = [\n",
    "    \"error_type\",\n",
    "    \"error_desc\",\n",
    "    \"OBJECTID\",\n",
    "    \"GlobalID\",\n",
    "    \"defGlobalID\",\n",
    "    \"CreationDate\",\n",
    "    \"Creator\",\n",
    "    \"Feature\",\n",
    "    \"Feature_Action\",\n",
    "    \"Quantity\",\n",
    "    \"Units\",\n",
    "    \"onsitematerials\",\n",
    "]\n",
    "\n",
    "WRITE_LOG = True\n",
    "\n",
    "# === LOGGING SETUP ===\n",
    "FILE_PATH = os.path.join(\n",
    "    OUTPUT_FOLDER, f\"{datetime.datetime.today().strftime('%Y-%m-%d')}_QC_summary.txt\"\n",
    ")\n",
    "handlers = [logging.StreamHandler(sys.stdout)]\n",
    "if WRITE_LOG:\n",
    "    handlers.append(logging.FileHandler(FILE_PATH, mode=\"w\", encoding=\"utf-8\"))\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\", handlers=handlers)\n",
    "\n",
    "# === HELPER FUNCTIONS ===\n",
    "def check_nulls(df, df_name, fields, error_list, summary_rows):\n",
    "    any_nulls = False\n",
    "    for field in fields:\n",
    "        if field in df.columns:\n",
    "            nulls = df[df[field].isnull()].copy()\n",
    "            if not nulls.empty:\n",
    "                any_nulls = True\n",
    "                nulls.loc[:, \"error_type\"] = \"nulls\"\n",
    "                nulls.loc[:, \"error_desc\"] = f\"NULL in {df_name} field: {field}\"\n",
    "                error_list.append(nulls)\n",
    "                msg = f\"{df_name}.{field}: {len(nulls)} nulls\"\n",
    "                logging.info(\"        \" + msg)\n",
    "                summary_rows.append(msg)\n",
    "        else:\n",
    "            logging.info(f\"        {field} not in {df_name}\")\n",
    "    if not any_nulls:\n",
    "        msg = f\"0 null errors found in {df_name}\"\n",
    "        logging.info(\"        \" + msg)\n",
    "        summary_rows.append(msg)\n",
    "\n",
    "\n",
    "def check_dates(df, df_name, date_field, error_list, summary_rows):\n",
    "    project_start_date = datetime.datetime(\n",
    "        PROJECT_START_YEAR, PROJECT_START_MONTH, PROJECT_START_DAY\n",
    "    )\n",
    "    today = datetime.datetime.today()\n",
    "    df[date_field] = pd.to_datetime(df[date_field], errors=\"coerce\")\n",
    "    invalid_dates = df[\n",
    "        (df[date_field] > today) | (df[date_field] < project_start_date)\n",
    "    ].copy()\n",
    "    if not invalid_dates.empty:\n",
    "        invalid_dates.loc[:, \"error_type\"] = \"dates\"\n",
    "        invalid_dates.loc[:, \"error_desc\"] = \"Invalid observation date\"\n",
    "        error_list.append(invalid_dates)\n",
    "    msg = f\"{len(invalid_dates)} records with invalid dates in {df_name}\"\n",
    "    logging.info(\"        \" + msg)\n",
    "    summary_rows.append(msg)\n",
    "\n",
    "\n",
    "def check_domains(df, df_name, domain_dict, error_list, summary_rows):\n",
    "    any_domain_errors = False\n",
    "    for d in domain_dict:\n",
    "        if d in df.columns:\n",
    "            valid_values = domain_dict[d]\n",
    "            invalid = df[~(df[d].isin(valid_values) | df[d].isnull())].copy()\n",
    "            if not invalid.empty:\n",
    "                any_domain_errors = True\n",
    "                invalid.loc[:, \"error_type\"] = \"domains\"\n",
    "                invalid.loc[:, \"error_desc\"] = invalid[d].apply(\n",
    "                    lambda x: f\"'{x}' not in domains for {d}\"\n",
    "                )\n",
    "                error_list.append(invalid)\n",
    "                msg = f\"Invalid entries for {d} in {df_name}: {list(invalid[d].dropna().unique())}\"\n",
    "                logging.info(\"        \" + msg)\n",
    "                summary_rows.append(msg)\n",
    "    if not any_domain_errors:\n",
    "        msg = f\"0 domain errors found in {df_name}\"\n",
    "        logging.info(\"        \" + msg)\n",
    "        summary_rows.append(msg)\n",
    "\n",
    "\n",
    "def check_repetitive_values(\n",
    "    df, df_name, fields, user_field, threshold, error_list, summary_rows\n",
    "):\n",
    "    grouped = df.groupby(user_field)\n",
    "    rep_error_count = 0\n",
    "    for user, group in grouped:\n",
    "        for field in fields:\n",
    "            if field in group.columns:\n",
    "                value_counts = group[field].value_counts(normalize=True)\n",
    "                dominant_values = value_counts[value_counts > threshold]\n",
    "                for val in dominant_values.index:\n",
    "                    rep_errors = group[group[field] == val].copy()\n",
    "                    rep_errors.loc[:, \"error_type\"] = \"repetitive\"\n",
    "                    rep_errors.loc[:, \"error_desc\"] = (\n",
    "                        f\"{user} repeated '{val}' in {df_name}.{field} over {int(threshold*100)}% of time\"\n",
    "                    )\n",
    "                    error_list.append(rep_errors)\n",
    "                    rep_error_count += len(rep_errors)\n",
    "    msg = (\n",
    "        f\"{rep_error_count} potentially repetitive inputs in {df_name}\"\n",
    "        if rep_error_count\n",
    "        else f\"0 potentially repetitive inputs in {df_name}\"\n",
    "    )\n",
    "    logging.info(\"        \" + msg)\n",
    "    summary_rows.append(msg)\n",
    "\n",
    "\n",
    "# --- Future helper functions: proximity checks, collector-region checks, etc. ---\n",
    "def check_proximity(df, other_layers, buffer_distance, error_list, summary_rows):\n",
    "    \"\"\"\n",
    "    Placeholder for proximity checks to trails or features.\n",
    "    `other_layers` can be a list of GeoDataFrames.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def check_collector_region(df, collector_dict, error_list, summary_rows):\n",
    "    \"\"\"\n",
    "    Placeholder for collector-region matching QC.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# === SUMMARY GENERATION ===\n",
    "start_time = datetime.datetime.now()\n",
    "summary_rows = []\n",
    "points_errors = []\n",
    "related_errors = []\n",
    "\n",
    "# load local data\n",
    "points_gdf = gpd.read_file(POINTS_FILE)\n",
    "related_df = (\n",
    "    pd.read_csv(RELATED_TABLE_FILE)\n",
    "    if os.path.exists(RELATED_TABLE_FILE)\n",
    "    else pd.DataFrame()\n",
    ")\n",
    "\n",
    "# summarize quality checks\n",
    "summary_rows.append(\"Null errors:\")\n",
    "check_nulls(points_gdf, \"points\", POINTS_REQUIRED_FIELDS, points_errors, summary_rows)\n",
    "if not related_df.empty:\n",
    "    check_nulls(\n",
    "        related_df, \"related\", RELATED_REQUIRED_FIELDS, related_errors, summary_rows\n",
    "    )\n",
    "\n",
    "summary_rows.append(\"Date errors:\")\n",
    "check_dates(points_gdf, \"points\", \"created_date\", points_errors, summary_rows)\n",
    "\n",
    "summary_rows.append(\"Domain errors:\")\n",
    "check_domains(points_gdf, \"points\", POINTS_DOMAINS, points_errors, summary_rows)\n",
    "if not related_df.empty:\n",
    "    check_domains(related_df, \"related\", RELATED_DOMAINS, related_errors, summary_rows)\n",
    "\n",
    "summary_rows.append(\"Repetitive value errors:\")\n",
    "check_repetitive_values(\n",
    "    points_gdf,\n",
    "    \"points\",\n",
    "    POINTS_REP_FIELDS,\n",
    "    \"created_user\",\n",
    "    THRESHOLD,\n",
    "    points_errors,\n",
    "    summary_rows,\n",
    ")\n",
    "if not related_df.empty:\n",
    "    check_repetitive_values(\n",
    "        related_df,\n",
    "        \"related\",\n",
    "        RELATED_REP_FIELDS,\n",
    "        \"Creator\",\n",
    "        THRESHOLD,\n",
    "        related_errors,\n",
    "        summary_rows,\n",
    "    )\n",
    "\n",
    "# output results\n",
    "output_xlsx = os.path.join(\n",
    "    OUTPUT_FOLDER, f\"{datetime.datetime.today().strftime('%Y-%m-%d')}_QC_report.xlsx\"\n",
    ")\n",
    "with pd.ExcelWriter(output_xlsx) as writer:\n",
    "    (\n",
    "        pd.concat(points_errors).to_excel(writer, sheet_name=\"points\", index=False)\n",
    "        if points_errors\n",
    "        else pd.DataFrame().to_excel(writer, sheet_name=\"points\")\n",
    "    )\n",
    "    (\n",
    "        pd.concat(related_errors).to_excel(writer, sheet_name=\"related\", index=False)\n",
    "        if related_errors\n",
    "        else pd.DataFrame().to_excel(writer, sheet_name=\"related\")\n",
    "    )\n",
    "    pd.DataFrame(summary_rows, columns=[\"summary\"]).to_excel(\n",
    "        writer, sheet_name=\"summary\", index=False\n",
    "    )\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "logging.info(\n",
    "    f\"\\nQC completed in {end_time - start_time}. Excel report saved to {output_xlsx}\"\n",
    ")\n",
    "if WRITE_LOG:\n",
    "    logging.info(f\"Log file saved to {FILE_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
